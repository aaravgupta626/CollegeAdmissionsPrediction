# -*- coding: utf-8 -*-
"""Admissions Prediction

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BLJcsGAXgwrj2hBUvCQucjBAfnJ0TCsm
"""

# Modules
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt, seaborn as sns
from sklearn.model_selection import train_test_split
import statsmodels.api as sm
from sklearn.feature_selection import RFE
from statsmodels.stats.outliers_influence import variance_inflation_factor
from sklearn.linear_model import LinearRegression

# Loading the dataset
df = pd.read_csv('https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/whitehat-ds-datasets/Admission_Predict.csv')
df.head()

# Checking for null values.
df.isnull().sum()

# Dropping 'Serial No.' column since it is irrelevant to the predicitons.
df.drop(columns=['Serial No.'], axis=1, inplace=True)
columns = [i.strip() for i in df.columns]
df.columns = columns

"""

---
***Finding Correlation***


---

"""

# Calculating correlation coefficient for all columns of the DataFrame
corr_df = df.corr()
# Using a heatmap to observe correlations.
plt.figure(figsize=(20,6))
sns.heatmap(corr_df, annot=True)
plt.show()

"""

---


***Train-Test Split***


---

"""

# Splitting the DataFrame into the training and test sets.
x = df.iloc[:, :-1]
y = df['Chance of Admit']
x_train, x_test, y_train, y_test = train_test_split = train_test_split(x, y, test_size=0.30, random_state=42)

"""

---
***Model Training***


---

"""

# Building the linear regression model.
x_train_ols = sm.add_constant(x_train)
ols_model = sm.OLS(y_train, x_train).fit()

# Printing the summary of the linear regression report.
print(ols_model.summary())

"""

---

***Determining Highly Correlated Features***


---

"""

# Creating a Python dictionary storing the moderately to highly correlated features with 'Chance of Admit' and the corresponding correlation values.
correlation_features_dict = {}

for i in range(len(columns)-1):
  temp = np.corrcoef(df[columns[i]], df['Chance of Admit'])[0][1]
  if temp >= 0.5:
    correlation_features_dict[columns[i]] = temp

correlation_features_dict

# Creating a heatmap to visualise the correlation between the above correlated features (if there exists).
plt.figure(figsize=(20,6))
sns.heatmap(df[correlation_features_dict.keys()].corr(), annot=True)
plt.show()

"""

---
***Recursive Feature Elimination***

---



"""

# RFE with 3-5 features.
lin_reg = LinearRegression()
rfe_1 = RFE(lin_reg, 4)
rfe_1.fit(df[correlation_features_dict.keys()], df['Chance of Admit'])

# Printing the 'support_' and 'ranking_' attributes to find out the features selected by RFE
print(rfe_1.support_)
print(rfe_1.ranking_)

# Printing the features selected by RFE in the previous step.
rfe_features = df[correlation_features_dict.keys()].columns[rfe_1.support_]
print(f'RFE selected features: {list(rfe_features)}')

# Building a linear regression model using the 'statsmodels.api' module having the above features selected by RFE.
# Subsetting the train set such that it contains only the above  selected features.
x_train_rfe = x_train[rfe_features]

# Adding the 'const' column to the features set.
x_train_rfe_ols = sm.add_constant(x_train_rfe)

# Fitting the model
ols_model_rfe = sm.OLS(y_train, x_train_rfe_ols).fit()

# Printing the summary of the linear regression report
print(ols_model_rfe.summary())

"""

---
***Variance Inflation Factor***


---


"""

# Checking for the VIF values of the features selected by RFE above.
vif_values = [(x_train_rfe_ols.columns[i], variance_inflation_factor(x_train_rfe_ols.values, i)) for i in range(x_train_rfe_ols.values.shape[1])]
# Creating a dataframe that will contain the names of all the feature variables and their respective VIFs.
vif_df = pd.DataFrame(vif_values, columns=['Feature', 'VIF'])
vif_df.head()